{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import shutil\n",
    "import time\n",
    "import math\n",
    "from collections import Counter\n",
    "import hashlib\n",
    "from  IPython.display import clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Dense,\n",
    "                          Dropout,\n",
    "                          Activation,\n",
    "                          BatchNormalization)\n",
    "from keras.models import model_from_json\n",
    "from keras import (losses,\n",
    "                   models,\n",
    "                   optimizers)\n",
    "from keras.activations import relu, softmax\n",
    "from keras.callbacks import (EarlyStopping,\n",
    "                             LearningRateScheduler,\n",
    "                             ModelCheckpoint,\n",
    "                             TensorBoard,\n",
    "                             ReduceLROnPlateau)\n",
    "from keras.layers import (Convolution1D,\n",
    "                          Dense,\n",
    "                          Dropout,\n",
    "                          GlobalAveragePooling1D, \n",
    "                          GlobalMaxPool1D, \n",
    "                          Input,\n",
    "                          MaxPool1D,\n",
    "                          concatenate)\n",
    "from keras.utils import (Sequence,\n",
    "                         to_categorical)\n",
    "\n",
    "from keras.layers import (Convolution2D,\n",
    "                          GlobalAveragePooling2D,\n",
    "                          BatchNormalization,\n",
    "                          Flatten,\n",
    "                          GlobalMaxPool2D,\n",
    "                          MaxPool2D,\n",
    "                          concatenate,\n",
    "                          Activation)\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import (StratifiedKFold,\n",
    "                                     KFold)\n",
    "from sklearn.utils import murmurhash3_32\n",
    "\n",
    "import wave\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "\n",
    "############################################\n",
    "import constants\n",
    "# from constants import *\n",
    "import utils\n",
    "from utils import (raw_labels_to_indices,\n",
    "                   PrepareData,\n",
    "                   get_class_weights,\n",
    "                   train_and_store_results,\n",
    "                   top_1_accuracy, top_2_accuracy, top_3_accuracy)\n",
    "import archs\n",
    "import archs_2\n",
    "from archs_2 import (get_1d_conv_model,\n",
    "                    get_general_2d_conv_model)\n",
    "\n",
    "SIZE = None\n",
    "LABELS = ['Hi-hat', 'Saxophone', 'Trumpet', 'Glockenspiel', 'Cello', 'Knock',\n",
    "       'Gunshot_or_gunfire', 'Clarinet', 'Computer_keyboard',\n",
    "       'Keys_jangling', 'Snare_drum', 'Writing', 'Laughter', 'Tearing',\n",
    "       'Fart', 'Oboe', 'Flute', 'Cough', 'Telephone', 'Bark', 'Chime',\n",
    "       'Bass_drum', 'Bus', 'Squeak', 'Scissors', 'Harmonica', 'Gong',\n",
    "       'Microwave_oven', 'Burping_or_eructation', 'Double_bass',\n",
    "       'Shatter', 'Fireworks', 'Tambourine', 'Cowbell', 'Electric_piano',\n",
    "       'Meow', 'Drawer_open_or_close', 'Applause', 'Acoustic_guitar',\n",
    "       'Violin_or_fiddle', 'Finger_snapping']\n",
    "COMPLETE_RUN = True\n",
    "SIZE_WHEN_NOT_COMPLETE_RUN = 50\n",
    "SAMPLE_RATE = 44100\n",
    "CONFIG_PATH = constants.CONFIG_PATH\n",
    "TRAIN_OFFLINE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 complete_run=None,\n",
    "                 size_when_not_complete_run=None,\n",
    "                 train_labels=None,\n",
    "                 sampling_rate=44100,\n",
    "                 audio_duration=2,\n",
    "                 n_classes=41,\n",
    "                 use_mfcc=False,\n",
    "                 n_mfcc=40,\n",
    "                 smooth_factor=0.1,\n",
    "\n",
    "                 n_folds=5,\n",
    "                 learning_rate=0.001, \n",
    "                 max_epochs=150,\n",
    "                 batch_size=64,\n",
    "                 \n",
    "                 kernel_size=(10, 4),\n",
    "                 depth_conv=4,\n",
    "                 depth_dense=1,\n",
    "                 dense_sizes=None,\n",
    "                 \n",
    "                 do_batch_normalization=False,\n",
    "                 dropout_rate=0.15,\n",
    "                 filters=32,\n",
    "                 filter_sizes=None,\n",
    "                 \n",
    "                 kernel_sizes_1d=None,\n",
    "                 maxpool_sizes_1d=None):\n",
    "        \n",
    "        if train_labels is None:\n",
    "            raise ValueError('You must specify train_labels for calculating class_weights')\n",
    "            \n",
    "        self.complete_run = complete_run or COMPLETE_RUN\n",
    "        self.size_when_not_complete_run = size_when_not_complete_run or SIZE_WHEN_NOT_COMPLETE_RUN\n",
    "        \n",
    "        self.smooth_factor = smooth_factor\n",
    "        self.class_weights = get_class_weights(train_labels, smooth_factor=self.smooth_factor)\n",
    "        \n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        \n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depth_conv = depth_conv\n",
    "        self.depth_dense = depth_dense\n",
    "        self.dense_sizes = dense_sizes  # or TODO\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.filters = filters\n",
    "        self.do_batch_normalization = do_batch_normalization\n",
    "        self.filter_sizes = filter_sizes  # or TODO\n",
    "        \n",
    "        self.kernel_sizes_1d = kernel_sizes_1d  # or TODO\n",
    "        self.maxpool_sizes_1d = maxpool_sizes_1d  # or  TODO\n",
    "        \n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length / 512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrepareData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StoreStatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_and_store_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------Begin Execution--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pd.read_csv(os.path.join(constants.DATADIR, \"train.csv\"))\n",
    "test_original = pd.read_csv(os.path.join(constants.DATADIR, \"sample_submission.csv\"))\n",
    "train_original['nframes'] = train_original['fname'].apply(\n",
    "    lambda f: wave.open(os.path.join(constants.DATADIR, 'audio_train/', f)).getnframes())\n",
    "test_original['nframes'] = test_original['fname'].apply(\n",
    "    lambda f: wave.open(os.path.join(constants.DATADIR, 'audio_test/', f)).getnframes())\n",
    "train_original_1 = train_original.set_index(\"fname\", inplace=False)\n",
    "test_original_1 = test_original.set_index(\"fname\", inplace=False)\n",
    "train_original_1['label_idx'] = raw_labels_to_indices(train_original_1[constants.LABEL])\n",
    "if not COMPLETE_RUN:\n",
    "    train_original_1 = train_original_1[:SIZE_WHEN_NOT_COMPLETE_RUN]\n",
    "    test_original_1 = test_original_1[:SIZE_WHEN_NOT_COMPLETE_RUN]\n",
    "\n",
    "# add offline for evaluating\n",
    "if COMPLETE_RUN:\n",
    "    train, train_offline = sklearn.model_selection.train_test_split(\n",
    "        train_original_1,\n",
    "        test_size=TRAIN_OFFLINE,\n",
    "        stratify=train_original_1['label_idx'])\n",
    "else:\n",
    "    train, train_offline = sklearn.model_selection.train_test_split(\n",
    "        train_original_1,\n",
    "        test_size=0.1)\n",
    "test = test_original_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    prepare_data_first\n",
    "except NameError:\n",
    "    prepare_data_first = PrepareData(preprocessing_fn=utils.audio_norm)\n",
    "    prepare_data_second = PrepareData(preprocessing_fn=utils.audio_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MFCC = 60\n",
    "AUDIO_DURATION = 2\n",
    "SMOOTH_FOR_CLASS_WEIGHTS = 10 # Amazing but this value won when expermenting with 0.1, 1, 100\n",
    "BATCH_SIZE = 64  # not too big, not too small\n",
    "KERNEL_SIZE = (6, 15)  # (6, 15) was good too ; (4, 10) is certainly nit bad\n",
    "\n",
    "DEPTH_CONV = 7  # TODO: en the end put 7. It is longer learning but better result; 4 for experimenting\n",
    "DEPTH_DENSE = 1  # 1 is the best\n",
    "FILTERS = 64  # 32 or 64?\n",
    "N_FOLDS = 10  # 2 or 5 or 10?\n",
    "USE_MFCC = True\n",
    "DROPOUT_RATE = 0.2  # 0.2 is better. And it seems that 0.3 is better too.\n",
    "\n",
    "DO_BATCH_NORMALIZATION = False\n",
    "DENSE_SIZES = None\n",
    "FILTER_SIZES = None\n",
    "KERNEL_SIZES_1D = None\n",
    "MAXPOOL_SIZES_1D = None\n",
    "\n",
    "# below dor 1d model and other notebook\n",
    "# DENSE_SIZES = [128]  # [128] won against [256] and [128, 128]\n",
    "# FILTER_SIZES = [16, 32, 32, 256]\n",
    "# DO_BATCH_NORMALIZATION = False  # False won\n",
    "# KERNEL_SIZES_1D = [9, 3, 3, 3]\n",
    "# MAXPOOL_SIZES_1D = [16, 4, 4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_to_create_model = get_general_2d_conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "do_kfold_now = True\n",
    "make_predictions = True\n",
    "slide_tick_for_first_epoch = None\n",
    "slide_tick = None\n",
    "verbose = 0\n",
    "\n",
    "for _ in range(1):\n",
    "    name_experiment = func_to_create_model.__name__\n",
    "    \n",
    "    ################# ATTEN #########################\n",
    "    name_experiment += '_2d_final'       \n",
    "\n",
    "    config_now = Config(\n",
    "        sampling_rate=44100,\n",
    "        use_mfcc=True,\n",
    "        audio_duration=AUDIO_DURATION,\n",
    "        n_mfcc=N_MFCC,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        smooth_factor=SMOOTH_FOR_CLASS_WEIGHTS,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        kernel_size=KERNEL_SIZE,\n",
    "        depth_conv=DEPTH_CONV,\n",
    "        depth_dense=DEPTH_DENSE,\n",
    "        train_labels=train.label_idx,\n",
    "        filters=FILTERS,\n",
    "        n_folds=N_FOLDS)\n",
    "    \n",
    "    config_now = Config(\n",
    "        complete_run=COMPLETE_RUN,\n",
    "        size_when_not_complete_run=SIZE_WHEN_NOT_COMPLETE_RUN,\n",
    "        sampling_rate=44100,\n",
    "        use_mfcc=USE_MFCC,\n",
    "        audio_duration=AUDIO_DURATION,\n",
    "        n_mfcc=N_MFCC,\n",
    "        train_labels=train.label_idx,\n",
    "        smooth_factor=SMOOTH_FOR_CLASS_WEIGHTS,\n",
    "        \n",
    "        n_folds=N_FOLDS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        \n",
    "        filters=FILTERS,\n",
    "        depth_conv=DEPTH_CONV,\n",
    "        depth_dense=DEPTH_DENSE,\n",
    "        kernel_size=KERNEL_SIZE,\n",
    "        \n",
    "        do_batch_normalization=DO_BATCH_NORMALIZATION,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        dense_sizes=DENSE_SIZES,\n",
    "        filter_sizes=FILTER_SIZES,\n",
    "        \n",
    "        kernel_sizes_1d=KERNEL_SIZES_1D,\n",
    "        maxpool_sizes_1d=MAXPOOL_SIZES_1D)\n",
    "\n",
    "    X_train_now = prepare_data_first(train, config_now, os.path.join(constants.DATA, 'audio_train'))\n",
    "    X_test_now = prepare_data_second(test, config_now, os.path.join(constants.DATA, 'audio_test'))\n",
    "    y_train_now = to_categorical(\n",
    "        train.label_idx, num_classes=len(constants.LABELS))\n",
    "\n",
    "    # standartization\n",
    "    if config_now.use_mfcc:\n",
    "        mean = np.mean(X_train_now, axis=0)\n",
    "        std = np.std(X_train_now, axis=0)\n",
    "        X_train_now = (X_train_now - mean) / std\n",
    "        X_test_now = (X_test_now - mean) / std               \n",
    "\n",
    "\n",
    "    name_experiment_final = name_experiment\n",
    "    print(name_experiment_final)\n",
    "    store_statistics_object = train_and_store_results(\n",
    "        name_experiment=name_experiment_final,\n",
    "        func_to_create_model=func_to_create_model,\n",
    "        config=config_now,\n",
    "        X_train=X_train_now,\n",
    "        y_train=y_train_now,\n",
    "        y_train_label_idx=train.label_idx,\n",
    "        X_test=X_test_now,\n",
    "        slide_tick_for_first_epoch=slide_tick_for_first_epoch,\n",
    "        verbose_keras=verbose,\n",
    "        make_predictions=make_predictions,\n",
    "        do_kfold=do_kfold_now)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
